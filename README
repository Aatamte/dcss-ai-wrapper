# README file for the dcss-ai-wrapper project.

#### Overview of this document: ######################################
#
# 1. Installing Dungeon Crawl Stone Soup
#
# 2. How to Run an agent in the terminal
#
# 3. Creating and using custom levels
#
# 4. Troubleshooting
#
######################################################################


######################################################################
# 0. Pre-requisites
######################################################################

This guide has been tested on Ubuntu 18.04 LTS and assumes you have the following installed:

    - git (sudo apt-get install git)
    - python2 (sudo apt-get install python2.7)
    - pip2 (sudo apt-get install python-pip)
    - python3 (sudo apt-get install python3.6)
    - pip3 (sudo apt-get install python3-pip)
    - A variety of packages required by Dungeon Crawl Stone Soup (sudo apt-get install build-essential libncursesw5-dev bison flex liblua5.1-0-dev libsqlite3-dev libz-dev pkg-config python-yaml libsdl2-image-dev libsdl2-mixer-dev libsdl2-dev libfreetype6-dev libpng-dev ttf-dejavu-core)

######################################################################
# 1. Installing Dungeon Crawl Stone Soup
######################################################################

While this API is likely to work with the current master branch, it has been tested with the 23.1 version, which
is the recommended version of crawl to use with this API. We recommend installing a local version of crawl inside this
project's folder.

    0. Make sure you have cloned this repository (dcss-ai-wrapper)
    
    1. Grab a copy of the 23.1 version of crawl, by cloning the repo and then resetting to the 23.1 version

       > cd ~/dcss-ai-wrapper/  (assuming this is the directory where you cloned this project - dcss-ai-wrapper)
       > git clone https://github.com/crawl/crawl.git
       > cd ~/dcss-ai-wrapper/crawl/
       > git reset --hard d6e21ad81dcba7f7f8c15336e0e985f070ce85fb
       > git submodule update --init

    2. Compile crawl with the following flags

       > cd ~/dcss-ai-wrapper/crawl/crawl-ref/source/
       > sudo make install prefix=/usr/local/ WEBTILES=y

    3. Install requirements to run the webserver version of the game

       > sudo pip2 install tornado==3.0.2
       > sudo pip3 install asyncio
       > sudo pip3 install websockets

    4. Test that the browser version of the game is working

       > cd ~/dcss-ai-wrapper/crawl/crawl-ref/source/
       > python2 webserver/server.py

       Now open your web browser and go to http://localhost:8080/

       Click register at the top right (not necessary to enter an email).

       Then after logging in, click the leftmost link under "Play now:" which is "DCSS trunk".
       You should then go to a menu where you choose your character configuration (i.e. species > background > weapon)
       Once you proceed through the menus you should find yourself in a newly generated world. If you've reached this
       step (and can see the tiles) you have successfully installed the game.

       Make sure you test the game is working in the browser before moving to Step 2.


######################################################################
# 2. How to Run an agent in the terminal
######################################################################

    1. Start a terminal version of crawl with a socket for our agent to connect to

       > cd ~/dcss-ai-wrapper/crawl/crawl-ref/source/
       > ./crawl -name AlexTheAgent -rc ./rcs/AlexTheAgent.rc -macro ./rcs/AlexTheAgent.macro -morgue ./rcs/midca -sprint -webtiles-socket ./rcs/AlexTheAgent:test.sock -await-connection

            This will now hang while waiting for out agent to connect

            Note: Feel free to change AlexTheAgent to any other string, this is just the name of the agent. Be sure
            to change it in all four places.

    2. Open up terminal_test_demo.py and change the variable 'crawl_socketpath' (line 14) to point to the location
       of the socket you just created.

    3. Run the demo script:

       > python2 terminal_test_demo.py

    4. You should now be able to watch the agent in the terminal as this script is running


######################################################################
# 3. Creating and using custom levels
######################################################################

# TODO...

######################################################################
# 4. Troubleshooting
######################################################################

  Problem: No images showing up and getting errors from the webserver like:
    'HTTPOutputError: Tried to write X number of bytes but error with content length'
  Solution: Make sure you are using tornado 3.0 (not the default version)

#### End README ######################################################

######################################################################
# Old README - might be useful
######################################################################


# Install

<<<<<<< HEAD
0. TODO: make a note about installing crawl first before testing webserver add info from INSTALL.txt, I had to sudo
make install prefix=/usr/local/ WEBTILES=y
=======
0. Clone the recent version of crawl from their github repository

1. copy over files for custom levels from our repo (under custom_sprint/) into crawl-ref/source/dat/des/sprint/

2. compile the crawl from step 0 by
    > cd crawl-ref/source
    > sudo make install prefix=/usr/local WEBTILES=y

* Note: anytime you change one of the custom sprint levels in source/dat/des/sprint/ you need to recompile the whole crawl game

>>>>>>> 371306fafd14d3907c21d755983935015ca8be36


1. For webserver (which uses python2)

pip install tornado==3.0.2

2. For Agent-based API (which uses python3)

sudo pip3 install asyncio
sudo pip3 install websockets 

# Problems that may arise:

[1] No images showing up and getting errors from the webserver like:
HTTPOutputError: Tried to write X number of bytes but error with content length
[SOLUTION:] use tornado 3.0 instead of the current version

[2] My custom sprint map isn't showing up!
[SOLUTION] Recompile the code (when you compile, it moves the maps to the install directory, and that's where the
webserver looks for the maps)

3. For learning, we need to install ILASP and the potassco asp tools (clingo, gringo, etc):

    a. Download ILASP here: https://sourceforge.net/projects/spikeimperial/files/ILASP/ILASP%20v3.1.0/

    - mv the ILASP executable somewhere system-wide (like /usr/local/bin/ ) or just make sure they are on the path

    - test the installation by running ILASP on the command line
      $ ILASP


    b. Download Potassco ASP tools from the most recent release here: https://github.com/potassco/clingo/releases/

    - mv the executables somewhere system-wide (like /usr/local/bin/ ) or just make sure they are on the path

     - test the installation by running clingo on the command line
      $ clingo


    c. Make sure there are empty folders named 'agent_data' and 'ilasp_data' and 'asp_data'


Resources:
-----------
# Induction Learner Tools:

[1] Download ILASP here:
https://sourceforge.net/projects/spikeimperial/?source=directory


sudo cp ILASP /usr/local/bin/             #(or somewhere else on your path)

[2] Download clingo and put all executables on the path
Clingo 5 release on github: https://github.com/potassco/clingo/releases

Choose the linux-x86_64.tar.gz

sudo cp clingo /usr/local/bin/
... (do the same for reify, gringo, clasp, and lpconvert)


# Running
----------

# 1. Start webserver

> cd crawl_18/crawl/crawl-ref/source/
> python2 webserver/server.py

# 2. now check to see if its up using a browser at localhost:8080

# 2.5. If this is the first time you are running this on your machine,
  you will need to register an account on the webserver (in the
  browser). Keep track of the username and password, as you will enter
  this into the code file, which the agent will use to connect to the
  server.

# 3. In a new terminal, go back to top level dir 

# 4. run the test_interface script using python3 (sidenote: installing asyncio
  on python2.x will initially work but then you get errors when trying
  to import it)

> python3 main.py



# Watching the Agent Play

# 1. Navigate your browser to localhost:8080

# 2. You should see a list of agents playing, click on the agent's name to spectate (note, you do not need to log in
# for this). If you don't see the agent on the list, try refreshing the page.